import streamlit as st
import os
import re
import io
import json
import tempfile
import logging
from datetime import datetime
from pptx import Presentation
from pptx.dml.color import RGBColor
from pptx.util import Inches, Pt
from pptx.enum.shapes import MSO_SHAPE_TYPE
from pptx.enum.text import PP_ALIGN, MSO_ANCHOR, MSO_AUTO_SIZE
import traceback
from PIL import Image, ImageEnhance, ImageFilter, ImageOps
import numpy as np

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.WARNING,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('presentation_analyzer.log'),
    ]
)
logger = logging.getLogger(__name__)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ Tesseract
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
    pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
    
    try:
        langs = pytesseract.get_languages()
        if 'rus' in langs and 'eng' in langs:
            OCR_LANGUAGES = 'rus+eng'
        elif 'rus' in langs:
            OCR_LANGUAGES = 'rus'
        else:
            OCR_LANGUAGES = 'eng'
    except:
        OCR_LANGUAGES = 'rus+eng'
        
except Exception as e:
    TESSERACT_AVAILABLE = False
    OCR_LANGUAGES = 'rus+eng'

def deduplicate_pptx(pptx_path: str) -> None:
    """–ü–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ—Ç PPTX –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤ –≤–Ω—É—Ç—Ä–∏ ZIP.
    PowerPoint –∏–Ω–æ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç '–æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏' –µ—Å–ª–∏ –≤ –∞—Ä—Ö–∏–≤–µ –µ—Å—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∏–º–µ–Ω–∞.
    """
    import zipfile, os, tempfile
    if not os.path.exists(pptx_path):
        return
    tmp_fd, tmp_path = tempfile.mkstemp(suffix=".pptx")
    os.close(tmp_fd)
    try:
        with zipfile.ZipFile(pptx_path, "r") as zin:
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
            names = zin.namelist()
            last_index = {}
            for i, n in enumerate(names):
                last_index[n] = i
            keep = {n for n,i in last_index.items()}
            with zipfile.ZipFile(tmp_path, "w", compression=zipfile.ZIP_DEFLATED) as zout:
                for i, n in enumerate(names):
                    if last_index.get(n) != i:
                        continue
                    zout.writestr(n, zin.read(n))
        os.replace(tmp_path, pptx_path)
    finally:
        try:
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
        except:
            pass


class PresentationAnalyzer:
    def __init__(self, pptx_path):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —Å –ø—É—Ç–µ–º –∫ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏"""
        self.pptx_path = pptx_path
        self.results = []
        self.used_fonts = set()
        self.ocr_languages = OCR_LANGUAGES
        self.full_ocr_texts = {}
        self.analysis_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.selected_slides_range = 'all'
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        self.settings = {
            'text_on_image_threshold': 0.3,
            'min_text_length_for_ocr': 3,
            'ocr_confidence_threshold': 0.6,
            'overlap_threshold': 0.2,
            'max_text_chars': 1000,
            'min_image_area_percentage': 0.7,
            'ocr_min_confidence': 45,
            'ocr_alternate_min_confidence': 35,
            'max_ocr_text_length': 5000,
        }
    
    def analyze_selected_slides(self, slides_range='all'):
        """–ê–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Å–ª–∞–π–¥–æ–≤"""
        try:
            self.selected_slides_range = slides_range
            
            prs = Presentation(self.pptx_path)
            total_slides = len(prs.slides)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–∏–µ —Å–ª–∞–π–¥—ã –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å
            slides_to_analyze = self.parse_slides_range(slides_range, total_slides)
            
            if not slides_to_analyze:
                return [], {}
            
            presentation_stats = {
                'has_animations': False,
                'has_transitions': False,
                'fonts_count': 0,
                'background_issues': 0,
                'text_on_images': 0,
                'total_images': 0,
                'ocr_used': False,
                'ocr_text_found': 0,
                'total_ocr_characters': 0,
                'selected_slides_count': len(slides_to_analyze),
                'selected_slides_range': slides_range,
                'total_slides_in_presentation': total_slides,
            }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É —Å–ª–∞–π–¥–∞–º–∏
            has_transitions = self.check_presentation_transitions(prs)
            presentation_stats['has_transitions'] = has_transitions
            
            for slide_num in slides_to_analyze:
                i = slide_num
                slide_result = self.analyze_slide(prs.slides[i-1], i)
                self.results.append(slide_result)
                
                if slide_result['–ê–Ω–∏–º–∞—Ü–∏–∏'] == '‚úó':
                    presentation_stats['has_animations'] = True
                if slide_result['–§–æ–Ω'] == '‚úó':
                    presentation_stats['background_issues'] += 1
                if slide_result['–¢–µ–∫—Å—Ç_–Ω–∞_–∏–∑–æ–±—Ä'] == '–î–∞':
                    presentation_stats['text_on_images'] += 1
                    presentation_stats['ocr_text_found'] += 1
                if slide_result['–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'] > 0:
                    presentation_stats['total_images'] += slide_result['–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è']
                
                if slide_result.get('OCR_—Ç–µ–∫—Å—Ç'):
                    presentation_stats['total_ocr_characters'] += len(slide_result['OCR_—Ç–µ–∫—Å—Ç'])
                    presentation_stats['ocr_used'] = True
            
            self.analyze_fonts()
            presentation_stats['fonts_count'] = len(self.used_fonts)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–µ OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self.save_full_ocr_results()
            
            return self.results, presentation_stats
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–ª–∞–π–¥–æ–≤: {e}")
            traceback.print_exc()
            return [], {}
    
    def calculate_conformance_percentage(self, results, presentation_stats):
        """–†–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫—Ä–∏—Ç–µ—Ä–∏—è–º"""
        try:
            total_slides = len(results)
            
            # –í–µ—Å–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫—Ä–∏—Ç–µ—Ä–∏—è
            weights = {
                'background': 15,      # –ë–µ–ª—ã–π —Ñ–æ–Ω –Ω–∞ –≤—Å–µ—Ö —Å–ª–∞–π–¥–∞—Ö
                'fonts': 15,           # –ù–µ –±–æ–ª–µ–µ 2 —à—Ä–∏—Ñ—Ç–æ–≤
                'text_overload': 10,   # –ù–µ –±–æ–ª–µ–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Å–ª–∞–π–¥–µ
                'text_on_images': 15,  # –ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
                'animations': 15,      # –ù–µ—Ç –∞–Ω–∏–º–∞—Ü–∏–π
                'transitions': 10,     # –ù–µ—Ç –ø–µ—Ä–µ—Ö–æ–¥–æ–≤
                'slide_compliance': 20 # –û–±—â–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–∞–∂–¥–æ–≥–æ —Å–ª–∞–π–¥–∞
            }
            
            total_possible = sum(weights.values())
            achieved_score = 0
            
            # 1. –ö—Ä–∏—Ç–µ—Ä–∏–π —Ñ–æ–Ω–∞
            background_issues = presentation_stats.get('background_issues', 0)
            if total_slides > 0:
                background_score = (total_slides - background_issues) / total_slides * weights['background']
            else:
                background_score = weights['background']
            achieved_score += background_score
            
            # 2. –ö—Ä–∏—Ç–µ—Ä–∏–π —à—Ä–∏—Ñ—Ç–æ–≤
            fonts_count = presentation_stats.get('fonts_count', 0)
            if fonts_count <= 2:
                fonts_score = weights['fonts']
            elif fonts_count <= 3:
                fonts_score = weights['fonts'] * 0.5
            else:
                fonts_score = 0
            achieved_score += fonts_score
            
            # 3. –ö—Ä–∏—Ç–µ—Ä–∏–π —Ç–µ–∫—Å—Ç–æ–≤–æ–π –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏
            text_issues = sum(1 for r in results if r['–¢–µ–∫—Å—Ç'] == '‚úó')
            if total_slides > 0:
                text_score = (total_slides - text_issues) / total_slides * weights['text_overload']
            else:
                text_score = weights['text_overload']
            achieved_score += text_score
            
            # 4. –ö—Ä–∏—Ç–µ—Ä–∏–π —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
            text_on_images = presentation_stats.get('text_on_images', 0)
            if total_slides > 0:
                images_score = (total_slides - text_on_images) / total_slides * weights['text_on_images']
            else:
                images_score = weights['text_on_images']
            achieved_score += images_score
            
            # 5. –ö—Ä–∏—Ç–µ—Ä–∏–π –∞–Ω–∏–º–∞—Ü–∏–π
            anim_issues = sum(1 for r in results if r['–ê–Ω–∏–º–∞—Ü–∏–∏'] == '‚úó')
            if total_slides > 0:
                anim_score = (total_slides - anim_issues) / total_slides * weights['animations']
            else:
                anim_score = weights['animations']
            achieved_score += anim_score
            
            # 6. –ö—Ä–∏—Ç–µ—Ä–∏–π –ø–µ—Ä–µ—Ö–æ–¥–æ–≤
            transition_issues = 1 if presentation_stats.get('has_transitions') else 0
            if transition_issues == 0:
                transition_score = weights['transitions']
            else:
                transition_score = 0
            achieved_score += transition_score
            
            # 7. –ö—Ä–∏—Ç–µ—Ä–∏–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–∞–π–¥–∞
            compliant_slides = 0
            for result in results:
                is_compliant = (
                    result['–§–æ–Ω'] == '‚úì' and
                    result['–®—Ä–∏—Ñ—Ç—ã'] == '‚úì' and
                    result['–¢–µ–∫—Å—Ç'] == '‚úì' and
                    result['–¢–µ–∫—Å—Ç_–Ω–∞_–∏–∑–æ–±—Ä'] == '–ù–µ—Ç' and
                    result['–ê–Ω–∏–º–∞—Ü–∏–∏'] == '‚úì'
                )
                if is_compliant:
                    compliant_slides += 1
            
            if total_slides > 0:
                slide_score = (compliant_slides / total_slides) * weights['slide_compliance']
            else:
                slide_score = weights['slide_compliance']
            achieved_score += slide_score
            
            # –†–∞—Å—á–µ—Ç –ø—Ä–æ—Ü–µ–Ω—Ç–∞
            percentage = (achieved_score / total_possible) * 100
            percentage = round(percentage, 1)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
            if percentage >= 90:
                readiness_level = "–æ—Ç–ª–∏—á–Ω–æ"
                readiness_color = "#27ae60"
                readiness_emoji = "üéâ"
            elif percentage >= 75:
                readiness_level = "—Ö–æ—Ä–æ—à–æ"
                readiness_color = "#2ecc71"
                readiness_emoji = "üëç"
            elif percentage >= 60:
                readiness_level = "—É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ"
                readiness_color = "#f39c12"
                readiness_emoji = "‚ö†Ô∏è"
            elif percentage >= 40:
                readiness_level = "—Ç—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏"
                readiness_color = "#e74c3c"
                readiness_emoji = "üîß"
            else:
                readiness_level = "–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –Ω–∏–∑–∫–∞—è"
                readiness_color = "#c0392b"
                readiness_emoji = "üö®"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–∂–Ω–æ –ª–∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –¥–∏–∑–∞–π–Ω–µ—Ä–∞–º
            can_send_to_designers = percentage >= 57
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
            criteria_details = {
                'background': {
                    'score': round(background_score, 1),
                    'max': weights['background'],
                    'issues': background_issues,
                    'total': total_slides,
                    'description': '–ë–µ–ª—ã–π —Ñ–æ–Ω –Ω–∞ –≤—Å–µ—Ö —Å–ª–∞–π–¥–∞—Ö'
                },
                'fonts': {
                    'score': round(fonts_score, 1),
                    'max': weights['fonts'],
                    'fonts_count': fonts_count,
                    'description': '–ù–µ –±–æ–ª–µ–µ 2 —à—Ä–∏—Ñ—Ç–æ–≤ –≤ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏'
                },
                'text_overload': {
                    'score': round(text_score, 1),
                    'max': weights['text_overload'],
                    'issues': text_issues,
                    'total': total_slides,
                    'description': '–ù–µ –±–æ–ª–µ–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Å–ª–∞–π–¥–µ'
                },
                'text_on_images': {
                    'score': round(images_score, 1),
                    'max': weights['text_on_images'],
                    'issues': text_on_images,
                    'total': total_slides,
                    'description': '–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö'
                },
                'animations': {
                    'score': round(anim_score, 1),
                    'max': weights['animations'],
                    'issues': anim_issues,
                    'total': total_slides,
                    'description': '–ù–µ—Ç –∞–Ω–∏–º–∞—Ü–∏–π –Ω–∞ —Å–ª–∞–π–¥–∞—Ö'
                },
                'transitions': {
                    'score': round(transition_score, 1),
                    'max': weights['transitions'],
                    'has_issues': transition_issues > 0,
                    'description': '–ù–µ—Ç –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –º–µ–∂–¥—É —Å–ª–∞–π–¥–∞–º–∏'
                },
                'slide_compliance': {
                    'score': round(slide_score, 1),
                    'max': weights['slide_compliance'],
                    'compliant': compliant_slides,
                    'total': total_slides,
                    'description': '–ü–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Å–ª–∞–π–¥—ã'
                }
            }
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            recommendations = []
            if percentage < 57:
                recommendations.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –¥–∏–∑–∞–π–Ω–µ—Ä–∞–º")
            if background_issues > 0:
                recommendations.append(f"–ò—Å–ø—Ä–∞–≤—å—Ç–µ —Ñ–æ–Ω –Ω–∞ {background_issues} —Å–ª–∞–π–¥–∞—Ö")
            if fonts_count > 2:
                recommendations.append(f"–£–º–µ–Ω—å—à–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à—Ä–∏—Ñ—Ç–æ–≤ —Å {fonts_count} –¥–æ 2")
            if text_issues > 0:
                recommendations.append(f"–£–º–µ–Ω—å—à–∏—Ç–µ —Ç–µ–∫—Å—Ç –Ω–∞ {text_issues} —Å–ª–∞–π–¥–∞—Ö")
            if text_on_images > 0:
                recommendations.append(f"–£–±–µ—Ä–∏—Ç–µ —Ç–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ {text_on_images} —Å–ª–∞–π–¥–∞—Ö")
            if anim_issues > 0:
                recommendations.append(f"–£–¥–∞–ª–∏—Ç–µ –∞–Ω–∏–º–∞—Ü–∏–∏ —Å {anim_issues} —Å–ª–∞–π–¥–æ–≤")
            if transition_issues > 0:
                recommendations.append("–£–¥–∞–ª–∏—Ç–µ –ø–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É —Å–ª–∞–π–¥–∞–º–∏")
            
            # –¢–µ–∫—Å—Ç –≤—ã–≤–æ–¥–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            if can_send_to_designers:
                user_message = f"üéâ –í–∞—à–∞ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º –Ω–∞ {percentage}%. –ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–∏–∑–∞–π–Ω–µ—Ä–∞–º!"
            else:
                user_message = f"‚ö†Ô∏è –í–∞—à–∞ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º –Ω–∞ {percentage}%. –ï—Å–ª–∏ –í—ã –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –¥–∏–∑–∞–π–Ω–µ—Ä–∞–º, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –µ—ë –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å."
            
            conformance_info = {
                'percentage': percentage,
                'readiness_level': readiness_level,
                'readiness_color': readiness_color,
                'readiness_emoji': readiness_emoji,
                'can_send_to_designers': can_send_to_designers,
                'criteria_details': criteria_details,
                'recommendations': recommendations,
                'user_message': user_message,
                'total_possible_score': total_possible,
                'achieved_score': round(achieved_score, 1),
                'compliant_slides': compliant_slides,
                'total_slides': total_slides
            }
            
            return conformance_info
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: {e}")
            return None
    
    def parse_slides_range(self, slides_range, total_slides):
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ —Å–ª–∞–π–¥–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å–ª–æ–∂–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
        slides_to_analyze = []
        
        try:
            # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—É—Å—Ç–æ–µ –∏–ª–∏ 'all', –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ —Å–ª–∞–π–¥—ã
            if not slides_range or str(slides_range).lower() == 'all':
                return list(range(1, total_slides + 1))
            
            slides_range = str(slides_range).strip()
            
            # –ï—Å–ª–∏ —ç—Ç–æ –æ–¥–Ω–æ —á–∏—Å–ª–æ
            if slides_range.isdigit():
                slide_num = int(slides_range)
                if 1 <= slide_num <= total_slides:
                    return [slide_num]
                else:
                    return []
            
            # –£–¥–∞–ª—è–µ–º –≤—Å–µ –ø—Ä–æ–±–µ–ª—ã –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            slides_range = slides_range.replace(' ', '')
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∑–∞–ø—è—Ç—ã—Ö (—Å–ø–∏—Å–æ–∫ —Å–ª–∞–π–¥–æ–≤)
            if ',' in slides_range:
                parts = slides_range.split(',')
                for part in parts:
                    if '-' in part:
                        # –î–∏–∞–ø–∞–∑–æ–Ω –≤–Ω—É—Ç—Ä–∏ —Å–ø–∏—Å–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "1-3,5-7")
                        range_parts = part.split('-')
                        if len(range_parts) == 2 and range_parts[0].isdigit() and range_parts[1].isdigit():
                            start = int(range_parts[0])
                            end = int(range_parts[1])
                            slides_to_analyze.extend(range(start, min(end, total_slides) + 1))
                    elif part.isdigit():
                        # –û–¥–∏–Ω –Ω–æ–º–µ—Ä —Å–ª–∞–π–¥–∞
                        slide_num = int(part)
                        if 1 <= slide_num <= total_slides:
                            slides_to_analyze.append(slide_num)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–µ—Ñ–∏—Å–∞ (–¥–∏–∞–ø–∞–∑–æ–Ω —Å–ª–∞–π–¥–æ–≤)
            elif '-' in slides_range:
                parts = slides_range.split('-')
                if len(parts) == 2 and parts[0].isdigit() and parts[1].isdigit():
                    start = int(parts[0])
                    end = int(parts[1])
                    slides_to_analyze = list(range(start, min(end, total_slides) + 1))
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
            slides_to_analyze = sorted(set(slides_to_analyze))
            
            # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ —Å–ª–∞–π–¥—ã
            if not slides_to_analyze:
                slides_to_analyze = list(range(1, total_slides + 1))
                self.selected_slides_range = 'all'
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ —Å–ª–∞–π–¥–æ–≤: {e}")
            slides_to_analyze = list(range(1, total_slides + 1))
            self.selected_slides_range = 'all'
        
        return slides_to_analyze
    
    def generate_word_report(self, results, presentation_stats, output_path=None):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Word (.docx)"""
        try:
            from docx import Document
            from docx.shared import Inches as DocxInches, Pt as DocxPt, RGBColor as DocxRGBColor
            from docx.enum.text import WD_ALIGN_PARAGRAPH
            
            doc = Document()
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title = doc.add_heading('–û—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏', 0)
            title.alignment = WD_ALIGN_PARAGRAPH.CENTER
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ
            doc.add_paragraph(f'–§–∞–π–ª: {os.path.basename(self.pptx_path)}')
            doc.add_paragraph(f'–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
            doc.add_paragraph(f'–í—Å–µ–≥–æ —Å–ª–∞–π–¥–æ–≤ –≤ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏: {presentation_stats.get("total_slides_in_presentation", len(results))}')
            doc.add_paragraph(f'–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å–ª–∞–π–¥–æ–≤: {len(results)}')
            doc.add_paragraph(f'–î–∏–∞–ø–∞–∑–æ–Ω –∞–Ω–∞–ª–∏–∑–∞: {self.selected_slides_range}')
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
            conformance_info = self.calculate_conformance_percentage(results, presentation_stats)
            
            if conformance_info:
                doc.add_paragraph()
                doc.add_heading('–£—Ä–æ–≤–µ–Ω—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∫—Ä–∏—Ç–µ—Ä–∏—è–º', level=1)
                
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –ø—Ä–æ—Ü–µ–Ω—Ç–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
                conformance_table = doc.add_table(rows=2, cols=2)
                conformance_table.style = 'LightShading-Accent1'
                
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫
                header_cells = conformance_table.rows[0].cells
                header_cells[0].text = '–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å'
                header_cells[1].text = '–ó–Ω–∞—á–µ–Ω–∏–µ'
                
                # –î–∞–Ω–Ω—ã–µ
                row_cells = conformance_table.rows[1].cells
                row_cells[0].text = '–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏—è–º'
                row_cells[1].text = f"{conformance_info['percentage']}% ({conformance_info['readiness_level']})"
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
                doc.add_paragraph()
                if conformance_info['can_send_to_designers']:
                    doc.add_paragraph(f"‚úÖ {conformance_info['user_message']}")
                else:
                    doc.add_paragraph(f"‚ö†Ô∏è {conformance_info['user_message']}")
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                if conformance_info['recommendations']:
                    doc.add_paragraph()
                    doc.add_heading('–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:', level=2)
                    for rec in conformance_info['recommendations']:
                        para = doc.add_paragraph()
                        para.add_run('‚Ä¢ ').bold = False
                        para.add_run(rec)
            
            doc.add_paragraph()
            
            # 1. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
            doc.add_heading('1. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏', level=1)
            
            recommendations = [
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ –±–æ–ª–µ–µ 2 —à—Ä–∏—Ñ—Ç–æ–≤ –≤ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏",
                "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–æ–Ω –≤—Å–µ—Ö —Å–ª–∞–π–¥–æ–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —à–∞–±–ª–æ–Ω—É",
                "–ò–∑–±–µ–≥–∞–π—Ç–µ –∞–Ω–∏–º–∞—Ü–∏–π –∏ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤",
                "–ù–µ —Ä–∞–∑–º–µ—â–∞–π—Ç–µ —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö",
                "–û–≥—Ä–∞–Ω–∏—á—å—Ç–µ —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–∞–π–¥–µ 1000 —Å–∏–º–≤–æ–ª–∞–º–∏",
                "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ –≤–º–µ—Å—Ç–æ —Ç–µ–∫—Å—Ç–∞ –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö"
            ]
            
            for rec in recommendations:
                paragraph = doc.add_paragraph()
                paragraph.add_run('‚Ä¢ ').bold = False
                paragraph.add_run(rec)
            
            doc.add_paragraph()
            
            # 2. –°–í–û–î–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê
            doc.add_heading('2. –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', level=1)
            
            stats_data = [
                ('–í—Å–µ–≥–æ —Å–ª–∞–π–¥–æ–≤', len(results)),
                ('–°–ª–∞–π–¥–æ–≤ —Å –Ω–∞—Ä—É—à–µ–Ω–∏—è–º–∏', sum(1 for r in results if r['–°—Ç–∞—Ç—É—Å'] != 'OK')),
                ('–§–æ–Ω –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —à–∞–±–ª–æ–Ω—É', presentation_stats.get('background_issues', 0)),
                ('–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —à—Ä–∏—Ñ—Ç–æ–≤', presentation_stats.get('fonts_count', 0)),
                ('–¢–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö', presentation_stats.get('text_on_images', 0)),
                ('–í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π', presentation_stats.get('total_images', 0)),
                ('–ê–Ω–∏–º–∞—Ü–∏–∏', '–î–∞' if presentation_stats.get('has_animations') else '–ù–µ—Ç'),
                ('–ü–µ—Ä–µ—Ö–æ–¥—ã', '–î–∞' if presentation_stats.get('has_transitions') else '–ù–µ—Ç'),
            ]
            
            stats_table = doc.add_table(rows=len(stats_data), cols=2)
            stats_table.style = 'LightShading-Accent1'
            
            for i, (key, value) in enumerate(stats_data):
                row_cells = stats_table.rows[i].cells
                row_cells[0].text = str(key)
                row_cells[1].text = str(value)
            
            doc.add_paragraph()
            doc.add_heading('3. –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Å–ª–∞–π–¥–∞–º', level=1)
            
            # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            slides_table = doc.add_table(rows=1, cols=9)
            slides_table.style = 'Table Grid'
            
            headers = ['–°–ª–∞–π–¥', '–ù–∞–ª–∏—á–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è', '–§–æ–Ω', '–®—Ä–∏—Ñ—Ç—ã', '–¢–µ–∫—Å—Ç', '–≠–ª–µ–º–µ–Ω—Ç—ã', '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è', '–¢–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä.', '–ê–Ω–∏–º–∞—Ü–∏–∏']
            header_cells = slides_table.rows[0].cells
            
            for i, header in enumerate(headers):
                header_cells[i].text = header
                header_cells[i].paragraphs[0].runs[0].bold = True
                header_cells[i].paragraphs[0].runs[0].font.size = DocxPt(9)
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
            for result in results:
                row_cells = slides_table.add_row().cells
                
                # –°–ª–∞–π–¥ –Ω–æ–º–µ—Ä
                row_cells[0].text = str(result['–°–ª–∞–π–¥'])
                row_cells[0].paragraphs[0].runs[0].font.size = DocxPt(9)
                
                # –ù–∞–ª–∏—á–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
                has_violation = result['–°—Ç–∞—Ç—É—Å'] != 'OK'
                row_cells[1].text = '–î–∞' if has_violation else '–ù–µ—Ç'
                if has_violation:
                    row_cells[1].paragraphs[0].runs[0].font.color.rgb = DocxRGBColor(255, 0, 0)
                row_cells[1].paragraphs[0].runs[0].font.size = DocxPt(9)
                
                # –§–æ–Ω
                row_cells[2].text = result['–§–æ–Ω']
                if result['–§–æ–Ω'] == '‚úó':
                    row_cells[2].paragraphs[0].runs[0].font.color.rgb = DocxRGBColor(255, 0, 0)
                row_cells[2].paragraphs[0].runs[0].font.size = DocxPt(9)
                
                # –®—Ä–∏—Ñ—Ç—ã
                row_cells[3].text = result['–®—Ä–∏—Ñ—Ç—ã']
                if result['–®—Ä–∏—Ñ—Ç—ã'] == '‚úó':
                    row_cells[3].paragraphs[0].runs[0].font.color.rgb = DocxRGBColor(255, 0, 0)
                row_cells[3].paragraphs[0].runs[0].font.size = DocxPt(9)
                
                # –¢–µ–∫—Å—Ç
                row_cells[4].text = result['–¢–µ–∫—Å—Ç_–¥–µ—Ç']
                if result['–¢–µ–∫—Å—Ç'] == '‚úó':
                    row_cells[4].paragraphs[0].runs[0].font.color.rgb = DocxRGBColor(255, 0, 0)
                row_cells[4].paragraphs[0].runs[0].font.size = DocxPt(9)
                
                # –≠–ª–µ–º–µ–Ω—Ç—ã
                row_cells[5].text = str(result['–≠–ª–µ–º–µ–Ω—Ç—ã'])
                row_cells[5].paragraphs[0].runs[0].font.size = DocxPt(9)
                
                # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                row_cells[6].text = str(result['–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'])
                row_cells[6].paragraphs[0].runs[0].font.size = DocxPt(9)
                
                # –¢–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
                row_cells[7].text = result['–¢–µ–∫—Å—Ç_–Ω–∞_–∏–∑–æ–±—Ä']
                if result['–¢–µ–∫—Å—Ç_–Ω–∞_–∏–∑–æ–±—Ä'] == '–î–∞':
                    row_cells[7].paragraphs[0].runs[0].font.color.rgb = DocxRGBColor(255, 0, 0)
                row_cells[7].paragraphs[0].runs[0].font.size = DocxPt(9)
                
                # –ê–Ω–∏–º–∞—Ü–∏–∏
                row_cells[8].text = result['–ê–Ω–∏–º–∞—Ü–∏–∏']
                if result['–ê–Ω–∏–º–∞—Ü–∏–∏'] == '‚úó':
                    row_cells[8].paragraphs[0].runs[0].font.color.rgb = DocxRGBColor(255, 0, 0)
                row_cells[8].paragraphs[0].runs[0].font.size = DocxPt(9)
            
            # 4. –¢–µ–∫—Å—Ç, –Ω–∞–π–¥–µ–Ω–Ω—ã–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö (OCR)
            if self.full_ocr_texts:
                doc.add_paragraph()
                doc.add_heading('4. –¢–µ–∫—Å—Ç, –Ω–∞–π–¥–µ–Ω–Ω—ã–π –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö (OCR)', level=1)
                
                for slide_num, ocr_data in self.full_ocr_texts.items():
                    doc.add_heading(f'–°–ª–∞–π–¥ {slide_num}', level=2)
                    doc.add_paragraph(f'–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ —Å–ª–∞–π–¥–µ: {ocr_data.get("image_count", 0)}')
                    doc.add_paragraph(f'–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å —Ç–µ–∫—Å—Ç–æ–º: {ocr_data.get("images_with_text", 0)}')
                    doc.add_paragraph(f'–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {ocr_data.get("confidence", 0):.1f}%')
                    doc.add_paragraph(f'–ú–µ—Ç–æ–¥: {ocr_data.get("method", "unknown")}')
                    
                    ocr_text = ocr_data.get('text', '')
                    if ocr_text:
                        if len(ocr_text) > 5000:
                            ocr_text = ocr_text[:5000] + '\n... [—Ç–µ–∫—Å—Ç —Å–æ–∫—Ä–∞—â–µ–Ω]'
                        
                        formatted_text = ocr_text.replace('--- –¢–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è', '\n--- –¢–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è')
                        text_paragraph = doc.add_paragraph(formatted_text)
                        text_paragraph.style = 'Normal'
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
            if output_path is None:
                output_path = f"report_{self.analysis_timestamp}.docx"
            
            doc.save(output_path)
            return output_path
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ Word –æ—Ç—á–µ—Ç–∞: {e}")
            traceback.print_exc()
            return None
    
    def save_full_ocr_results(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω—ã—Ö OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        try:
            for slide_result in self.results:
                if slide_result.get('OCR_—Ç–µ–∫—Å—Ç'):
                    slide_num = slide_result['–°–ª–∞–π–¥']
                    self.full_ocr_texts[slide_num] = {
                        'text': slide_result.get('OCR_—Ç–µ–∫—Å—Ç', ''),
                        'confidence': slide_result.get('OCR_—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å', 0),
                        'method': slide_result.get('OCR_–º–µ—Ç–æ–¥', ''),
                        'image_count': slide_result['–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'],
                        'images_with_text': slide_result.get('OCR_–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π_—Å_—Ç–µ–∫—Å—Ç–æ–º', 0)
                    }
            
        except Exception as e:
            pass
    
    def check_presentation_transitions(self, prs):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –º–µ–∂–¥—É —Å–ª–∞–π–¥–∞–º–∏"""
        try:
            for slide in prs.slides:
                try:
                    slide_xml = str(slide.element.xml).lower()
                    if any(keyword in slide_xml for keyword in ['p:transition', 'transition']):
                        return True
                except:
                    continue
        except:
            pass
        return False
    
    def analyze_slide(self, slide, slide_num):
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Å–ª–∞–π–¥–∞"""
        slide_result = {
            '–°–ª–∞–π–¥': slide_num,
            '–°—Ç–∞—Ç—É—Å': 'OK',
            '–ù–∞—Ä—É—à–µ–Ω–∏—è': [],
            '–®—Ä–∏—Ñ—Ç—ã': '‚úì',
            '–¢–µ–∫—Å—Ç': '‚úì',
            '–ê–Ω–∏–º–∞—Ü–∏–∏': '‚úì',
            '–ü–µ—Ä–µ—Ö–æ–¥—ã': '‚úì',
            '–§–æ–Ω': '‚úì',
            '–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è': 0,
            '–¢–µ–∫—Å—Ç_–Ω–∞_–∏–∑–æ–±—Ä': '–ù–µ—Ç',
            '–¢–µ–∫—Å—Ç_–¥–µ—Ç': '',
            '–≠–ª–µ–º–µ–Ω—Ç—ã': len(slide.shapes),
            'OCR_—Ç–µ–∫—Å—Ç': '',
            'OCR_—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': 0,
            'OCR_–º–µ—Ç–æ–¥': '',
            'OCR_–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π_—Å_—Ç–µ–∫—Å—Ç–æ–º': 0,
        }
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ–Ω–∞
        if not self.check_background_comprehensive(slide):
            slide_result['–§–æ–Ω'] = '‚úó'
            slide_result['–ù–∞—Ä—É—à–µ–Ω–∏—è'].append('–§–û–ù')
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞
        text_overload, char_count = self.check_text_improved(slide)
        slide_result['–¢–µ–∫—Å—Ç_–¥–µ—Ç'] = f"{char_count} —Å–∏–º–≤."
        if text_overload:
            slide_result['–¢–µ–∫—Å—Ç'] = '‚úó'
            slide_result['–ù–∞—Ä—É—à–µ–Ω–∏—è'].append(f'–¢–ï–ö–°–¢({char_count})')
        
        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–∏–º–∞—Ü–∏–π
        if self.check_animations_improved(slide):
            slide_result['–ê–Ω–∏–º–∞—Ü–∏–∏'] = '‚úó'
            slide_result['–ù–∞—Ä—É—à–µ–Ω–∏—è'].append('–ê–ù–ò–ú–ê–¶–ò–ò')
        
        # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        has_text_on_images, image_count, ocr_data = self.check_images_enhanced(slide)
        slide_result['–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è'] = image_count
        
        if ocr_data:
            full_text = ocr_data.get('text', '')
            slide_result['OCR_—Ç–µ–∫—Å—Ç'] = full_text[:self.settings['max_ocr_text_length']]
            slide_result['OCR_—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å'] = ocr_data.get('confidence', 0)
            slide_result['OCR_–º–µ—Ç–æ–¥'] = ocr_data.get('method', '')
            slide_result['OCR_–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π_—Å_—Ç–µ–∫—Å—Ç–æ–º'] = ocr_data.get('images_with_text', 0)
        
        if has_text_on_images:
            slide_result['–¢–µ–∫—Å—Ç_–Ω–∞_–∏–∑–æ–±—Ä'] = '–î–∞'
            slide_result['–ù–∞—Ä—É—à–µ–Ω–∏—è'].append('–¢–ï–ö–°–¢_–ù–ê_–ò–ó–û–ë–†')
        
        # 5. –°–±–æ—Ä —à—Ä–∏—Ñ—Ç–æ–≤
        self.collect_fonts(slide)
        
        if slide_result['–ù–∞—Ä—É—à–µ–Ω–∏—è']:
            slide_result['–°—Ç–∞—Ç—É—Å'] = ', '.join(slide_result['–ù–∞—Ä—É—à–µ–Ω–∏—è'])
        
        return slide_result
    
    def check_background_comprehensive(self, slide):
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ–Ω–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ–Ω–∞ —Å–ª–∞–π–¥–∞
            if slide.background:
                fill = slide.background.fill
                if fill.type == 1:
                    if hasattr(fill.fore_color, 'rgb'):
                        color = fill.fore_color.rgb
                        if hasattr(color, 'r'):
                            if not (color.r == 255 and color.g == 255 and color.b == 255):
                                return False
                        elif color != RGBColor(255, 255, 255):
                            return False
                elif fill.type != 0:
                    return False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä—É–ø–Ω—ã—Ö —Ñ–∏–≥—É—Ä
            try:
                slide_width = slide.width if hasattr(slide, 'width') else Inches(10)
                slide_height = slide.height if hasattr(slide, 'height') else Inches(7.5)
                slide_area = slide_width * slide_height
                
                for shape in slide.shapes:
                    try:
                        shape_area = shape.width * shape.height
                        if shape_area > slide_area * self.settings['min_image_area_percentage']:
                            if hasattr(shape, 'fill'):
                                fill = shape.fill
                                if fill.type == 1:
                                    if hasattr(fill.fore_color, 'rgb'):
                                        color = fill.fore_color.rgb
                                        if hasattr(color, 'r'):
                                            if not (color.r == 255 and color.g == 255 and color.b == 255):
                                                return False
                                        elif color != RGBColor(255, 255, 255):
                                            return False
                    except:
                        continue
            except:
                pass
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ XML –Ω–∞ —Ü–≤–µ—Ç–∞
            try:
                slide_xml = str(slide.element.xml).lower()
                
                hex_pattern = r'#[0-9a-f]{6}'
                hex_matches = re.findall(hex_pattern, slide_xml)
                for hex_color in hex_matches:
                    if hex_color != '#ffffff' and hex_color != '#ffffff00':
                        return False
                
                rgb_pattern = r'rgb\((\d+),\s*(\d+),\s*(\d+)\)'
                rgb_matches = re.findall(rgb_pattern, slide_xml)
                for r, g, b in rgb_matches:
                    if int(r) != 255 or int(g) != 255 or int(b) != 255:
                        return False
            except:
                pass
            
            return True
            
        except:
            return False
    
    def check_text_improved(self, slide):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        try:
            total_chars = 0
            for shape in slide.shapes:
                if hasattr(shape, "text_frame") and shape.text_frame.text:
                    text = shape.text_frame.text.strip()
                    if text and len(text) > 1:
                        clean_text = re.sub(r'\s+', ' ', text)
                        total_chars += len(clean_text)
            
            return total_chars > self.settings['max_text_chars'], total_chars
        except:
            return False, 0
    
    def check_animations_improved(self, slide):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–∏–º–∞—Ü–∏–π"""
        try:
            xml = str(slide.element.xml).lower()
            animation_patterns = [
                r'<p:anim\s', r'p:ctn', r'p:seq', r'p:par',
                r'dur=["\']', r'accel=["\']', r'decel=["\']',
                r'<p:custanim\s', r'<p:set\s', r'animate\s',
                r'animation\s', r'animbullet\s', r'animeffect\s'
            ]
            
            for pattern in animation_patterns:
                if re.search(pattern, xml):
                    return True
            
            return False
        except:
            return False
    
    def check_images_enhanced(self, slide):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –Ω–∏—Ö"""
        try:
            image_count = 0
            has_text_on_images = False
            ocr_data = {}
            
            image_info = []
            text_shapes = []
            
            def process_shape(shape):
                nonlocal image_count
                
                if hasattr(shape, 'shapes'):
                    for subshape in shape.shapes:
                        process_shape(subshape)
                    return
                
                if hasattr(shape, "image"):
                    image_count += 1
                    try:
                        img_info = {
                            'shape': shape,
                            'id': id(shape),
                            'index': image_count,
                            'width': shape.width,
                            'height': shape.height,
                            'format': shape.image.ext,
                        }
                        image_info.append(img_info)
                    except:
                        return
                
                if hasattr(shape, "text_frame"):
                    text = shape.text_frame.text
                    if text and text.strip():
                        try:
                            text_shape_info = {
                                'shape': shape,
                                'id': id(shape),
                                'left': shape.left,
                                'top': shape.top,
                                'width': shape.width,
                                'height': shape.height,
                                'right': shape.left + shape.width,
                                'bottom': shape.top + shape.height,
                                'text': text.strip(),
                                'char_count': len(text.strip())
                            }
                            text_shapes.append(text_shape_info)
                        except:
                            return
            
            for shape in slide.shapes:
                process_shape(shape)
            
            if not image_info:
                return False, 0, None
            
            # –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            for text_shape in text_shapes:
                if text_shape['char_count'] < self.settings['min_text_length_for_ocr']:
                    continue
                    
                for img in image_info:
                    if self.shapes_overlap_improved(text_shape, img):
                        has_text_on_images = True
                        break
                
                if has_text_on_images:
                    break
            
            # OCR –ø—Ä–æ–≤–µ—Ä–∫–∞
            if TESSERACT_AVAILABLE and len(image_info) > 0:
                try:
                    ocr_results = self.check_images_with_multiple_ocr_methods(slide, image_info)
                    
                    combined_text = ""
                    total_confidence = 0
                    images_with_text = 0
                    best_method = ""
                    best_confidence = 0
                    
                    img_info_dict = {img['id']: img for img in image_info}
                    
                    for img_id, (ocr_text, confidence, img_format, method) in ocr_results.items():
                        if self.is_meaningful_text(ocr_text) and confidence > self.settings['ocr_alternate_min_confidence']:
                            if combined_text:
                                combined_text += f"\n\n--- –¢–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {img_info_dict[img_id]['index']} ({img_info_dict[img_id]['width']:.0f}x{img_info_dict[img_id]['height']:.0f}) ---\n"
                            else:
                                combined_text += f"--- –¢–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {img_info_dict[img_id]['index']} ({img_info_dict[img_id]['width']:.0f}x{img_info_dict[img_id]['height']:.0f}) ---\n"
                            
                            combined_text += ocr_text
                            total_confidence += confidence
                            images_with_text += 1
                            
                            if confidence > best_confidence:
                                best_confidence = confidence
                                best_method = method
                    
                    if combined_text:
                        has_text_on_images = True
                        avg_confidence = total_confidence / images_with_text if images_with_text > 0 else 0
                        
                        ocr_data = {
                            'text': combined_text,
                            'confidence': avg_confidence,
                            'method': best_method if best_method else "multiple",
                            'image_count': len(image_info),
                            'images_with_text': images_with_text
                        }
                        
                except Exception as e:
                    pass
            
            return has_text_on_images, len(image_info), ocr_data
            
        except Exception as e:
            return False, 0, None
    
    def shapes_overlap_improved(self, shape1, shape2):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Ñ–∏–≥—É—Ä"""
        try:
            overlap_x = not (shape1['right'] <= shape2['left'] or shape1['left'] >= shape2['right'])
            overlap_y = not (shape1['bottom'] <= shape2['top'] or shape1['top'] >= shape2['bottom'])
            return overlap_x and overlap_y
        except:
            return False
    
    def check_images_with_multiple_ocr_methods(self, slide, image_info):
        """OCR –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""
        try:
            ocr_results = {}
            
            with tempfile.TemporaryDirectory() as temp_dir:
                for i, img_info in enumerate(image_info):
                    try:
                        shape = img_info['shape']
                        
                        if shape.width < 50 or shape.height < 50:
                            continue
                        
                        image_data = shape.image.blob
                        img_format = img_info.get('format', 'unknown')
                        
                        best_result = self.try_multiple_ocr_methods(image_data, img_format, img_info['index'], img_info['id'])
                        
                        if best_result:
                            text, confidence, method_used = best_result
                            ocr_results[img_info['id']] = (text, confidence, img_format, method_used)
                            
                    except Exception as e:
                        continue
            
            return ocr_results
            
        except Exception as e:
            return {}
    
    def try_multiple_ocr_methods(self, image_data, img_format, index, img_id):
        """–ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Ç–æ–¥–æ–≤ OCR"""
        best_text = ""
        best_confidence = 0
        best_method = ""
        
        ocr_methods = [
            {'name': 'Tesseract_PSM6_rus+eng', 'config': '--oem 3 --psm 6 -l rus+eng', 'preprocess': 'standard'},
            {'name': 'Tesseract_PSM3_rus+eng', 'config': '--oem 3 --psm 3 -l rus+eng', 'preprocess': 'standard'},
            {'name': 'Tesseract_PSM11_rus+eng', 'config': '--oem 3 --psm 11 -l rus+eng', 'preprocess': 'high_contrast'},
        ]
        
        for method in ocr_methods:
            try:
                processed_image = self.preprocess_for_ocr_method(image_data, img_format, index, img_id, method['preprocess'])
                
                if processed_image is None:
                    continue
                
                data = pytesseract.image_to_data(processed_image, config=method['config'], output_type=pytesseract.Output.DICT)
                
                text_parts = []
                confidences = []
                
                for j in range(len(data['text'])):
                    text_item = data['text'][j].strip()
                    if text_item and len(text_item) > 1:
                        text_parts.append(text_item)
                        if data['conf'][j] != '-1':
                            confidences.append(float(data['conf'][j]))
                
                if text_parts:
                    text = ' '.join(text_parts).strip()
                    avg_confidence = sum(confidences) / len(confidences) if confidences else 0
                    
                    text = self.clean_ocr_text(text)
                    
                    if text and avg_confidence > best_confidence:
                        if self.quick_text_quality_check(text, avg_confidence):
                            best_text = text
                            best_confidence = avg_confidence
                            best_method = method['name']
                            
            except Exception as e:
                continue
        
        if best_text and best_confidence > self.settings['ocr_alternate_min_confidence']:
            return best_text, best_confidence, best_method
        
        return None
    
    def preprocess_for_ocr_method(self, image_data, img_format, index, img_id, method='standard'):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            img = Image.open(io.BytesIO(image_data))
            
            if img.mode in ('RGBA', 'LA', 'P'):
                background = Image.new('RGB', img.size, (255, 255, 255))
                if img.mode == 'RGBA':
                    background.paste(img, mask=img.split()[3])
                else:
                    background.paste(img)
                img = background
            elif img.mode != 'RGB':
                img = img.convert('RGB')
            
            img = img.convert('L')
            
            if method == 'standard':
                enhancer = ImageEnhance.Sharpness(img)
                img = enhancer.enhance(2.0)
                enhancer = ImageEnhance.Contrast(img)
                img = enhancer.enhance(1.5)
                img = ImageOps.autocontrast(img, cutoff=2)
            elif method == 'high_contrast':
                enhancer = ImageEnhance.Contrast(img)
                img = enhancer.enhance(3.0)
                img = ImageOps.autocontrast(img, cutoff=5)
                threshold = 200
                img = img.point(lambda p: 255 if p > threshold else 0)
            elif method == 'inverted':
                img = ImageOps.invert(img)
                enhancer = ImageEnhance.Sharpness(img)
                img = enhancer.enhance(2.0)
                enhancer = ImageEnhance.Contrast(img)
                img = enhancer.enhance(1.5)
                img = ImageOps.autocontrast(img, cutoff=2)
            
            return img
            
        except Exception as e:
            return None
    
    def clean_ocr_text(self, text):
        """–û—á–∏—Å—Ç–∫–∞ OCR —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return text
        
        lines = text.split('\n')
        clean_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            alpha_count = sum(1 for c in line if c.isalpha())
            total_chars = len(line)
            
            if total_chars > 0 and alpha_count / total_chars > 0.3:
                clean_lines.append(line)
        
        text = '\n'.join(clean_lines)
        
        replacements = {
            '–°–±–µ—Ä—ë': '–°–±–µ—Ä', '–°–±–µ—Ä–™': '–°–±–µ—Ä', '—Å–±–µ—Ä—ë': '—Å–±–µ—Ä',
            '–°–ë–ï–†—ë': '–°–ë–ï–†', '—ë': '–µ', '–Å': '–ï',
            '""': '"', "''": "'", '``': '`', '``': '"',
            '‚Äù': '"', '‚Äû': '"', '¬´': '"', '¬ª': '"',
            '‚Äî': '-', '‚Äì': '-', '`': "'", '¬¥': "'",
            '‚Äò': "'", '‚Äô': "'",
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        text = re.sub(r'\s[–∞-—è–ê-–Øa-zA-Z]\s', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def quick_text_quality_check(self, text, confidence):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ç–µ–∫—Å—Ç–∞"""
        if not text or len(text) < 10:
            return False
        
        russian_letters = sum(1 for c in text if '–∞' <= c.lower() <= '—è' or c in '—ë–µ')
        total_letters = sum(1 for c in text if c.isalpha())
        
        if total_letters == 0:
            return False
        
        russian_ratio = russian_letters / total_letters if total_letters > 0 else 0
        
        if confidence < 50 and russian_ratio < 0.8:
            return False
        elif russian_ratio < 0.5:
            return False
        
        russian_words = re.findall(r'\b[–ê-–Ø–∞-—è—ë–Å]{3,}\b', text)
        if len(russian_words) < 2:
            return False
        
        for word in russian_words:
            if len(word) > 10:
                if any(word.count(word[i:i+3]) > 2 for i in range(len(word)-2)):
                    return False
        
        return True
    
    def is_meaningful_text(self, text):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–Ω–∞—á–∏–º–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return False
        
        text = self.clean_ocr_text(text)
        
        if len(text) < 20:
            return False
        
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        if len(lines) < 1:
            return False
        
        meaningful_lines = 0
        
        for line in lines:
            if len(line) < 5:
                continue
            
            russian_letters = sum(1 for c in line if '–∞' <= c.lower() <= '—è' or c in '—ë–µ')
            total_chars = len(line)
            russian_words = re.findall(r'\b[–ê-–Ø–∞-—è—ë–Å]{3,}\b', line)
            
            is_text_like = (
                russian_letters > 5 and
                len(russian_words) > 1 and
                russian_letters / total_chars > 0.4
            )
            
            if is_text_like:
                meaningful_lines += 1
        
        return meaningful_lines >= 1
    
    def collect_fonts(self, slide):
        """–°–±–æ—Ä —à—Ä–∏—Ñ—Ç–æ–≤"""
        try:
            for shape in slide.shapes:
                if hasattr(shape, "text_frame"):
                    for paragraph in shape.text_frame.paragraphs:
                        for run in paragraph.runs:
                            if hasattr(run.font, 'name') and run.font.name:
                                font_name = run.font.name
                                if font_name and font_name.strip():
                                    self.used_fonts.add(font_name.strip())
        except:
            pass
    
    def analyze_fonts(self):
        """–ê–Ω–∞–ª–∏–∑ —à—Ä–∏—Ñ—Ç–æ–≤"""
        try:
            filtered_fonts = set()
            system_fonts = [
                '+mj-lt', '+mn-lt', 'calibri', 'tahoma', 'arial', 
                'times', 'verdana', 'cambria', 'segoe ui', 'consolas',
                'courier new', 'georgia', 'impact', 'trebuchet ms'
            ]
            
            for font in self.used_fonts:
                font_lower = font.lower()
                is_system_font = False
                
                for sys_font in system_fonts:
                    if sys_font in font_lower:
                        is_system_font = True
                        break
                
                if not is_system_font:
                    filtered_fonts.add(font)
            
            font_count = len(filtered_fonts)
            
            for result in self.results:
                if font_count > 2:
                    result['–®—Ä–∏—Ñ—Ç—ã'] = '‚úó'
                    if '–®–†–ò–§–¢–´' not in result['–ù–∞—Ä—É—à–µ–Ω–∏—è']:
                        result['–ù–∞—Ä—É—à–µ–Ω–∏—è'].append(f'–®–†–ò–§–¢–´({font_count})')
                        result['–°—Ç–∞—Ç—É—Å'] = ', '.join(result['–ù–∞—Ä—É—à–µ–Ω–∏—è'])
            
        except:
            pass